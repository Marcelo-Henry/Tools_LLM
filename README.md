<p align="center">
    <img src="LLM.png" alt="LLM" width="300">
</p>

<p align="center">
<strong>Onde LLMs Locais ganham mÃ£os para trabalhar com arquivos e conhecimento.</strong>
</p>

Um agente autÃ´nomo que permite sua LLM local (LM Studio/Ollama) executar aÃ§Ãµes reais no sistema de arquivos, com sistema RAG opcional para memÃ³ria de longo prazo.

## ğŸš€ InÃ­cio RÃ¡pido

```bash
# Instalar dependÃªncias
pip install -r requirements.txt --break-system-packages

# Ou

pip3 install -r requirements.txt --break-system-packages

# Configurar URL do servidor LLM
# Edite agent.py linha 6: BASE_URL = "http://localhost:1234/v1"

# Executar
python main.py

# Ou

python3 main.py

# Ver ajuda
> /help
```

## âœ¨ Funcionalidades

### ğŸ”„ Sistema de Undo
- Snapshots automÃ¡ticos antes de operaÃ§Ãµes destrutivas
- `/undo` para reverter Ãºltima aÃ§Ã£o
- HistÃ³rico completo de operaÃ§Ãµes em `.undo_history/`
- RestauraÃ§Ã£o segura de arquivos deletados ou modificados

### ğŸ§  Planejamento Multi-Step
- DetecÃ§Ã£o automÃ¡tica de tarefas complexas
- Preview do plano antes da execuÃ§Ã£o
- ConfirmaÃ§Ã£o interativa (y/n)
- Evita aÃ§Ãµes acidentais em operaÃ§Ãµes em lote

### ğŸ“Š Gerenciamento de Contexto
- CompressÃ£o inteligente de histÃ³rico
- Truncamento de outputs longos
- Evita overflow de context window
- MantÃ©m informaÃ§Ãµes essenciais
- Limite de 20 mensagens no histÃ³rico

### âš¡ Comandos Ocultos
- `!comando` - Executa comandos shell diretos (fora da sandbox, timeout 120s)
- `clear` - Limpa a tela sem afetar o histÃ³rico do agente

## ğŸ› ï¸ Tools DisponÃ­veis

O agente possui acesso Ã s seguintes ferramentas:

- **list_files** - Listar arquivos em um diretÃ³rio
- **read_file** - Ler conteÃºdo de arquivos
- **write_file** - Criar novos arquivos
- **edit_file** - Editar arquivos existentes
- **delete_file** - Deletar arquivos
- **shell** - Executar comandos shell (timeout 10s)

Todas as operaÃ§Ãµes sÃ£o executadas dentro da pasta `./sandbox` por seguranÃ§a.

## ğŸ“š Sistema RAG (Opcional)

Sistema de memÃ³ria de longo prazo com lazy loading - sÃ³ carrega quando necessÃ¡rio.

### Comandos:

```bash
/rag                      # Ver ajuda e status
/rag enable               # Habilitar RAG (carrega modelo)
/rag disable              # Desabilitar RAG
/rag status               # Ver status atual
/rag add <texto>          # Adicionar texto
/rag add file:<path>      # Adicionar arquivo(s)
/rag view                 # Listar documentos
/rag clear                # Limpar base de conhecimento
```

**CaracterÃ­sticas:**
- âœ… Lazy loading - inicia instantaneamente
- âœ… Busca semÃ¢ntica com embeddings
- âœ… Suporta mÃºltiplos arquivos com glob patterns
- âœ… PersistÃªncia em ChromaDB

## ğŸ’¡ Exemplos de Uso

### ConversaÃ§Ã£o Natural
```
> crie um arquivo hello.py que imprime olÃ¡ mundo
> liste os arquivos
> leia o arquivo hello.py
> execute o comando python hello.py
> delete o arquivo hello.py
```

### Tarefas Complexas
```
> Eu tenho 5 arquivos, delete apenas os que dizem ser nÃ£o importantes
> Analise todos os arquivos .py e adicione docstrings onde faltam
> Refatore o cÃ³digo para seguir PEP8
```

### Comandos Diretos (Ocultos)
```
# Eles sÃ£o apenas exemplos:
> !ls -la                 # Executa comando no terminal (fora da sandbox)
> !git status             # Qualquer comando shell
> !python script.py       # Executa scripts
> clear                   # Limpa a tela (mantÃ©m histÃ³rico)
```

### Com RAG Habilitado
```
> /rag enable
> /rag add file:docs/*.txt
> Do que vocÃª sabe com o RAG?
```

**Dica:** Use `/help` para ver mais exemplos e comandos disponÃ­veis.

## âš™ï¸ ConfiguraÃ§Ã£o

**Servidor LLM:**
- Edite `BASE_URL` em `agent.py` (linha 6)
- CompatÃ­vel com LM Studio, Ollama, ou qualquer servidor OpenAI-compatible

**Sandbox:**
- Todas as operaÃ§Ãµes de arquivo ocorrem em `./sandbox`
- Para mudar, edite `BASE_DIR` em `tools.py`

## ğŸ“¦ DependÃªncias

```
As dependÃªncias necessÃ¡rias estÃ£o em requirements.txt
```

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Este projeto foca em simplicidade e eficiÃªncia.
